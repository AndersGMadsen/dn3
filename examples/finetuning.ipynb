{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Fine-tuning\n",
    "-----------\n",
    "More and more state-of-the-art deep neural-network like classifiers perform a procedure of pretraining\n",
    "using immense general purpose datasets, then *fine-tuning* on smaller application-focused examples.\n",
    "\n",
    "We show how this premise can be used from the perspective of a large dataset of many people, and see each\n",
    "person as a fine-tuning opportunity. This is very-similar to the un-aligned/DA/DG case of fine-tuning from\n",
    "the Kostas and Rudzicz 2020 (under review) paper.\n",
    "\n",
    "To keep things as simple as possible, we use pretty much the same configuration and, as much as possible, code\n",
    "as the `Basics` example. Return to that if anything is confusing.\n",
    "\n",
    "```yaml\n",
    "DN3:\n",
    "  datasets:\n",
    "    - mmidb\n",
    "\n",
    "training_configuration:\n",
    "  use_gpu: False\n",
    "  folds: 5\n",
    "  epochs: 10\n",
    "  batch_size: 16\n",
    "  fine_tuning:\n",
    "    test_fraction: 0.5\n",
    "    epochs: 2\n",
    "    rate: 1e-5\n",
    "\n",
    "mmidb:\n",
    "  name: \"Physionet MMIDB\"\n",
    "  toplevel: /path/to/the/toplevel/folder\n",
    "  tmin: 0\n",
    "  tlen: 6\n",
    "  events:\n",
    "    - T1\n",
    "    - T2\n",
    "  exclude_sessions:\n",
    "    - \"*R0[!6].edf\"    # equivalently \"*R0[12345789].edf\"\n",
    "    - \"*R1[!04].edf\"   # equivalently \"*R1[123].edf\"\n",
    "  exclude_people:\n",
    "    - S088\n",
    "    - S090\n",
    "    - S092\n",
    "    - S100\n",
    "```\n",
    "\n",
    "Below we will start with some identical code to load our dataset, and prepare a TIDNet model for classification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning ../tests/test_dataset. If there are a lot of files, this may take a while...: 100%|██████████| 4/4 [00:00<00:00, 76.23it/s, extension=.gdf]\n",
      "Loading Physionet MMIDB: 100%|██████████| 105/105 [00:25<00:00,  4.16person/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 datasets.\n",
      "Creating dataset of 420 Epoched recordings from 105 people.\n"
     ]
    }
   ],
   "source": [
    "from dn3.configuratron import ExperimentConfig\n",
    "from dn3.trainable.processes import StandardClassification\n",
    "from dn3.trainable.models import TIDNet\n",
    "\n",
    "# Since we are doing a lot of loading, this is nice to suppress some tedious information\n",
    "import mne\n",
    "mne.set_log_level(False)\n",
    "\n",
    "config_filename = 'my_config.yml'\n",
    "experiment = ExperimentConfig(config_filename)\n",
    "dataset = experiment.datasets['mmidb']\n",
    "\n",
    "dataset = dataset.auto_construct_dataset()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This time, we will also create two functions that exhibit the two different (though not necessarily mutually exclusive)\n",
    "way one might adjust from one domain to a slightly different one. Freezing and fine-tuning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def frozen_tuning(training_data, testing_data, model):\n",
    "    model.freeze_features()\n",
    "    tune_process = StandardClassification(model, learning_rate=experiment.training_configuration.fine_tuning.rate)\n",
    "    tune_process.fit(training_data, epochs=experiment.training_configuration.fine_tuning.epochs,\n",
    "                     batch_size=experiment.training_configuration.batch_size)\n",
    "    # We unfreeze so that the model can be subsequently trained again\n",
    "    model.freeze_features(unfreeze=True)\n",
    "    return tune_process.evaluate(testing_data)\n",
    "\n",
    "def fine_tuning(training_data, testing_data, model):\n",
    "    tune_process = StandardClassification(model, learning_rate=experiment.training_configuration.fine_tuning.rate)\n",
    "    tune_process.fit(training_data, epochs=experiment.training_configuration.fine_tuning.epochs,\n",
    "                     batch_size=experiment.training_configuration.batch_size)\n",
    "    return tune_process.evaluate(testing_data)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll make some helpers to compare the tuned performance for three possible scenarios:\n",
    "\n",
    "    1. Freeze features with a new classifier\n",
    "    2. The same as the above, but then fine-tune *all weights* including the new final layer\n",
    "    3. Just fine-tuning all the general weights from the start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def tuning_performance_comparison(training_data, testing_data, model):\n",
    "    just_tune_model = model.clone()\n",
    "    just_tune_performance = fine_tuning(training_data, testing_data, just_tune_model)\n",
    "\n",
    "    freeze_performance = frozen_tuning(training_data, testing_data, model)\n",
    "    freeze_then_tune = fine_tuning(training_data, testing_data, model)\n",
    "\n",
    "    return dict(tuned=just_tune_performance, frozen=freeze_performance, freeze_then_tune=freeze_then_tune)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now everything runs pretty much the same as our basic process, with person-specific performance reporting. Except this\n",
    "time, we will compare the different tuning techniques instead of just evaluating the model with our test person."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "results = list()\n",
    "for training, validation, test in dataset.lmso(experiment.training_configuration.folds):\n",
    "    tidnet = TIDNet.from_dataset(dataset, targets=2)\n",
    "    process = StandardClassification(tidnet, cuda=experiment.training_configuration.use_gpu)\n",
    "\n",
    "    # General training\n",
    "    process.fit(training_dataset=training, validation_dataset=validation,\n",
    "                epochs=experiment.training_configuration.epochs,\n",
    "                batch_size=experiment.training_configuration.batch_size)\n",
    "\n",
    "    # Tuning\n",
    "    for _, _, test_thinker in test.loso():\n",
    "        # First split the test_thinker further for training and testing (the middle return value would be validation)\n",
    "        tune_train, _, tune_test = test_thinker.split(\n",
    "            test_frac=experiment.training_configuration.fine_tuning.test_fraction, validation_frac=0)\n",
    "\n",
    "        results.append(tuning_performance_comparison(tune_train, tune_test, tidnet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use a `DataFrame` this time to compare the performances a little more elegantly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "results = DataFrame(results)\n",
    "\n",
    "print(results)\n",
    "print(results.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-80d8433b",
   "language": "python",
   "display_name": "PyCharm (DN3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}