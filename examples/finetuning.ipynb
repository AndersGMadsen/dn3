{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Fine-tuning\n",
    "-----------\n",
    "More and more state-of-the-art deep neural-network like classifiers perform a procedure of pretraining\n",
    "using immense general purpose datasets, then *fine-tuning* on smaller application-focused examples.\n",
    "\n",
    "We show how this premise can be used from the perspective of a large dataset of many people, and see each\n",
    "person as a fine-tuning opportunity. This is very-similar to the un-aligned/DA/DG case of fine-tuning from\n",
    "the Kostas and Rudzicz 2020 (under review) paper.\n",
    "\n",
    "To keep things as simple as possible, we use pretty much the same configuration and, as much as possible, code\n",
    "as the `Basics` example. Return to that if anything is confusing.\n",
    "\n",
    "```yaml\n",
    "DN3:\n",
    "  datasets:\n",
    "    - mmidb\n",
    "\n",
    "training_configuration:\n",
    "  use_gpu: False\n",
    "  folds: 5\n",
    "  epochs: 10\n",
    "  batch_size: 16\n",
    "  fine_tuning:\n",
    "    test_fraction: 0.5\n",
    "    epochs: 2\n",
    "    rate: 1e-5\n",
    "\n",
    "mmidb:\n",
    "  name: \"Physionet MMIDB\"\n",
    "  toplevel: /path/to/the/toplevel/folder\n",
    "  tmin: 0\n",
    "  tlen: 6\n",
    "  events:\n",
    "    - T1\n",
    "    - T2\n",
    "  exclude_sessions:\n",
    "    - \"*R0[!6].edf\"    # equivalently \"*R0[12345789].edf\"\n",
    "    - \"*R1[!04].edf\"   # equivalently \"*R1[123].edf\"\n",
    "  exclude_people:\n",
    "    - S088\n",
    "    - S090\n",
    "    - S092\n",
    "    - S100\n",
    "```\n",
    "\n",
    "Below we will start with some identical code to load our dataset, and prepare a TIDNet model for classification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scanning ../tests/test_dataset. If there are a lot of files, this may take a while...: 100%|██████████| 4/4 [00:00<00:00, 91.52it/s, extension=.gdf]\n",
      "Loading Physionet MMIDB: 100%|██████████| 105/105 [00:23<00:00,  4.48person/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 datasets.\n",
      "Creating dataset of 420 Epoched recordings from 105 people.\n"
     ]
    }
   ],
   "source": [
    "from dn3.configuratron import ExperimentConfig\n",
    "from dn3.trainable.processes import StandardClassification\n",
    "from dn3.trainable.models import TIDNet\n",
    "\n",
    "# Since we are doing a lot of loading, this is nice to suppress some tedious information\n",
    "import mne\n",
    "mne.set_log_level(False)\n",
    "\n",
    "config_filename = 'my_config.yml'\n",
    "experiment = ExperimentConfig(config_filename)\n",
    "dataset = experiment.datasets['mmidb']\n",
    "\n",
    "dataset = dataset.auto_construct_dataset()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This time, we will also create two functions that exhibit the two different (though not necessarily mutually exclusive)\n",
    "way one might adjust from one domain to a slightly different one. Freezing and fine-tuning."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "def frozen_tuning(training_data, testing_data, model):\n",
    "    model.freeze_features()\n",
    "    tune_process = StandardClassification(model, learning_rate=experiment.training_configuration.fine_tuning.rate)\n",
    "    tune_process.fit(training_data, epochs=experiment.training_configuration.fine_tuning.epochs,\n",
    "                     batch_size=experiment.training_configuration.batch_size)\n",
    "    # We unfreeze so that the model can be subsequently trained again\n",
    "    model.freeze_features(unfreeze=True)\n",
    "    return tune_process.evaluate(testing_data)\n",
    "\n",
    "def fine_tuning(training_data, testing_data, model):\n",
    "    tune_process = StandardClassification(model, learning_rate=experiment.training_configuration.fine_tuning.rate)\n",
    "    tune_process.fit(training_data, epochs=experiment.training_configuration.fine_tuning.epochs,\n",
    "                     batch_size=experiment.training_configuration.batch_size)\n",
    "    return tune_process.evaluate(testing_data)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll make some helpers to compare the tuned performance for three possible scenarios:\n",
    "\n",
    "    1. Freeze features with a new classifier\n",
    "    2. The same as the above, but then fine-tune *all weights* including the new final layer\n",
    "    3. Just fine-tuning all the general weights from the start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def tuning_performance_comparison(training_data, testing_data, model):\n",
    "    just_tune_model = model.clone()\n",
    "    just_tune_performance = fine_tuning(training_data, testing_data, just_tune_model)\n",
    "\n",
    "    freeze_performance = frozen_tuning(training_data, testing_data, model)\n",
    "    freeze_then_tune = fine_tuning(training_data, testing_data, model)\n",
    "\n",
    "    return dict(tuned=just_tune_performance, frozen=freeze_performance, freeze_then_tune=freeze_then_tune)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now everything runs pretty much the same as our basic process, with person-specific performance reporting. Except this\n",
    "time, we will compare the different tuning techniques instead of just evaluating the model with our test person."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: PYDEVD_USE_CYTHON environment variable is set to 'NO'. Frame evaluator will be also disabled because it requires Cython extensions to be enabled in order to operate correctly.\n",
      "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Iteration:   0%|          | 0/166 [00:00<?, ?it/s]\u001B[A\n",
      "Iteration:   0%|          | 0/166 [00:23<?, ?it/s, Accuracy=0.5, loss=0.978]\u001B[A\n",
      "Iteration:   1%|          | 1/166 [00:23<1:05:41, 23.89s/it, Accuracy=0.5, loss=0.978]\u001B[A\n",
      "Iteration:   1%|          | 1/166 [00:24<1:05:41, 23.89s/it, Accuracy=0.5, loss=1.18] \u001B[A\n",
      "Iteration:   1%|          | 2/166 [00:24<45:58, 16.82s/it, Accuracy=0.5, loss=1.18]  \u001B[A\n",
      "Iteration:   1%|          | 2/166 [00:24<45:58, 16.82s/it, Accuracy=0.688, loss=0.677]\u001B[A\n",
      "Iteration:   2%|▏         | 3/166 [00:24<32:14, 11.87s/it, Accuracy=0.688, loss=0.677]\u001B[A\n",
      "Iteration:   2%|▏         | 3/166 [00:24<32:14, 11.87s/it, Accuracy=0.625, loss=0.71] \u001B[A\n",
      "Iteration:   2%|▏         | 4/166 [00:24<22:44,  8.42s/it, Accuracy=0.625, loss=0.71]\u001B[A\n",
      "Iteration:   2%|▏         | 4/166 [00:25<22:44,  8.42s/it, Accuracy=0.625, loss=1.15]\u001B[A\n",
      "Iteration:   3%|▎         | 5/166 [00:25<16:04,  5.99s/it, Accuracy=0.625, loss=1.15]\u001B[A\n",
      "Iteration:   3%|▎         | 5/166 [00:25<16:04,  5.99s/it, Accuracy=0.562, loss=1.05]\u001B[A\n",
      "Iteration:   4%|▎         | 6/166 [00:25<11:26,  4.29s/it, Accuracy=0.562, loss=1.05]\u001B[A\n",
      "Iteration:   4%|▎         | 6/166 [00:25<11:26,  4.29s/it, Accuracy=0.625, loss=1.11]\u001B[A\n",
      "Iteration:   4%|▍         | 7/166 [00:25<08:13,  3.10s/it, Accuracy=0.625, loss=1.11]\u001B[A\n",
      "Iteration:   4%|▍         | 7/166 [00:26<08:13,  3.10s/it, Accuracy=0.438, loss=1.24]\u001B[A\n",
      "Iteration:   5%|▍         | 8/166 [00:26<05:58,  2.27s/it, Accuracy=0.438, loss=1.24]\u001B[A\n",
      "Iteration:   5%|▍         | 8/166 [00:26<05:58,  2.27s/it, Accuracy=0.562, loss=1.05]\u001B[A\n",
      "Iteration:   5%|▌         | 9/166 [00:26<04:24,  1.68s/it, Accuracy=0.562, loss=1.05]\u001B[A\n",
      "Iteration:   5%|▌         | 9/166 [00:26<04:24,  1.68s/it, Accuracy=0.438, loss=1.24]\u001B[A\n",
      "Iteration:   6%|▌         | 10/166 [00:26<03:19,  1.28s/it, Accuracy=0.438, loss=1.24]\u001B[A\n",
      "Iteration:   6%|▌         | 10/166 [00:27<03:19,  1.28s/it, Accuracy=0.562, loss=1.1] \u001B[A\n",
      "Iteration:   7%|▋         | 11/166 [00:27<02:35,  1.01s/it, Accuracy=0.562, loss=1.1]\u001B[A\n",
      "Iteration:   7%|▋         | 11/166 [00:27<02:35,  1.01s/it, Accuracy=0.25, loss=1.21]\u001B[A\n",
      "Iteration:   7%|▋         | 12/166 [00:27<02:05,  1.23it/s, Accuracy=0.25, loss=1.21]\u001B[A\n",
      "Iteration:   7%|▋         | 12/166 [00:28<02:05,  1.23it/s, Accuracy=0.438, loss=1.61]\u001B[A\n",
      "Iteration:   8%|▊         | 13/166 [00:28<01:49,  1.39it/s, Accuracy=0.438, loss=1.61]\u001B[A\n",
      "Iteration:   8%|▊         | 13/166 [00:28<01:49,  1.39it/s, Accuracy=0.5, loss=1.08]  \u001B[A\n",
      "Iteration:   8%|▊         | 14/166 [00:28<01:35,  1.59it/s, Accuracy=0.5, loss=1.08]\u001B[A\n",
      "Iteration:   8%|▊         | 14/166 [00:28<01:35,  1.59it/s, Accuracy=0.5, loss=1.3] \u001B[A\n",
      "Iteration:   9%|▉         | 15/166 [00:28<01:24,  1.78it/s, Accuracy=0.5, loss=1.3]\u001B[A\n",
      "Iteration:   9%|▉         | 15/166 [00:29<01:24,  1.78it/s, Accuracy=0.375, loss=1.28]\u001B[A\n",
      "Iteration:  10%|▉         | 16/166 [00:29<01:17,  1.94it/s, Accuracy=0.375, loss=1.28]\u001B[A\n",
      "Iteration:  10%|▉         | 16/166 [00:29<01:17,  1.94it/s, Accuracy=0.562, loss=1.01]\u001B[A\n",
      "Iteration:  10%|█         | 17/166 [00:29<04:20,  1.75s/it, Accuracy=0.562, loss=1.01]\u001B[A\n",
      "Epoch:   0%|          | 0/10 [00:29<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-4-0989b7fb7b54>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m     \u001B[0;31m# General training\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m     process.fit(training_dataset=training, validation_dataset=validation,\n\u001B[0m\u001B[1;32m      9\u001B[0m                 \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mexperiment\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtraining_configuration\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mepochs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m                 batch_size=experiment.training_configuration.batch_size)\n",
      "\u001B[0;32m~/Documents/Thesis/DNPT/dn3/trainable/processes.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, training_dataset, epochs, validation_dataset, step_callback, epoch_callback, batch_size, **loader_kwargs)\u001B[0m\n\u001B[1;32m    267\u001B[0m             \u001B[0mdata_iterator\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_dataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    268\u001B[0m             \u001B[0;32mfor\u001B[0m \u001B[0miteration\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpbar\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 269\u001B[0;31m                 \u001B[0minputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mget_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata_iterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    270\u001B[0m                 \u001B[0moutputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    271\u001B[0m                 \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcalculate_loss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Thesis/DNPT/dn3/trainable/processes.py\u001B[0m in \u001B[0;36mget_batch\u001B[0;34m(iterator)\u001B[0m\n\u001B[1;32m    257\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    258\u001B[0m         \u001B[0;32mdef\u001B[0m \u001B[0mget_batch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 259\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    260\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    261\u001B[0m         \u001B[0mvalidation_log\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    343\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    344\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__next__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 345\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    346\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    347\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_kind\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0m_DatasetKind\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mIterable\u001B[0m \u001B[0;32mand\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    383\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    384\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 385\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    386\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    387\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     43\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mauto_collation\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 44\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0midx\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0midx\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     45\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Thesis/DNPT/dn3/data/dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, item)\u001B[0m\n\u001B[1;32m    628\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    629\u001B[0m             \u001B[0msample_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mitem\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcumulative_sizes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mperson_id\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 630\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_thinkers\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_thinkers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mperson_id\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msample_idx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    631\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    632\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturn_person_id\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Thesis/DNPT/dn3/data/dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, item, return_id)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    388\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreturn_id\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 389\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mConcatDataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    390\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreturn_session_id\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    391\u001B[0m             \u001B[0msession_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbisect\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbisect_right\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcumulative_sizes\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mitem\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m    205\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    206\u001B[0m             \u001B[0msample_idx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0midx\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcumulative_sizes\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdataset_idx\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 207\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdataset_idx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0msample_idx\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    208\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    209\u001B[0m     \u001B[0;34m@\u001B[0m\u001B[0mproperty\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Thesis/DNPT/dn3/data/dataset.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, index)\u001B[0m\n\u001B[1;32m    268\u001B[0m                 \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Using trial {} in place for now...\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    269\u001B[0m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__getitem__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 270\u001B[0;31m             \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnormalizer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msqueeze\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    271\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cache\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    272\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_cache\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Documents/Thesis/DNPT/dn3/utils.py\u001B[0m in \u001B[0;36mmin_max_normalize\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[0;32mdef\u001B[0m \u001B[0mmin_max_normalize\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     31\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 32\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmax\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     33\u001B[0m     \u001B[0;32melif\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m3\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkeepdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "results = list()\n",
    "for training, validation, test in dataset.lmso(experiment.training_configuration.folds):\n",
    "    tidnet = TIDNet.from_dataset(dataset, targets=2)\n",
    "    process = StandardClassification(tidnet, cuda=experiment.training_configuration.use_gpu)\n",
    "\n",
    "    # General training\n",
    "    process.fit(training_dataset=training, validation_dataset=validation,\n",
    "                epochs=experiment.training_configuration.epochs,\n",
    "                batch_size=experiment.training_configuration.batch_size)\n",
    "\n",
    "    # Tuning\n",
    "    for _, _, test_thinker in test.loso():\n",
    "        # First split the test_thinker further for training and testing (the middle return value would be validation)\n",
    "        tune_train, _, tune_test = test_thinker.split(\n",
    "            test_frac=experiment.training_configuration.fine_tuning.test_fraction, validation_frac=0)\n",
    "\n",
    "        results.append(tuning_performance_comparison(tune_train, tune_test, tidnet))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's use a `DataFrame` this time to compare the performances a little more elegantly."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "results = DataFrame(results)\n",
    "\n",
    "print(results)\n",
    "print(results.describe())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-80d8433b",
   "language": "python",
   "display_name": "PyCharm (DN3)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}